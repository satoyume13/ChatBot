model_path:
  small: 'Mistral-7B-Instruct-v0.1-GGUF/mistral-7b-instruct-v0.1.Q3_K_M.gguf'
  large: 'Mistral-7B-Instruct-v0.1-GGUF/mistral-7b-instruct-v0.1.Q5_K_M.gguf'

model_type: 'mistral'


embeddings_path: 'BAAI/bge-large-en-v1.5'

model_config: ('max_new_tokens': 512, 'temperature' : 0 ,'context_length': 4096 ,'gpu_layers' : 0) # 32 to put all mistral layers on GPU, might differ for other models

  